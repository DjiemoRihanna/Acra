"""
Module ML - Entra√Ænement des mod√®les Scikit-learn pour ACRA SOC
"""
import os
import joblib
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import logging
import threading
import time

from src.extensions import db
from src.models import NetworkFlow, Alert
from src.core.event_bus import bus

class MLTrainer:
    """
    Entra√Ænement des mod√®les de Machine Learning
    Utilise Scikit-learn pour la d√©tection d'anomalies
    """
    
    def __init__(self, app=None):
        self.app = app
        self.running = True
        self.thread = None
        self.models_path = "/app/data/ml_models/"
        os.makedirs(self.models_path, exist_ok=True)
        
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Configuration
        self.retrain_interval = int(os.getenv('ML_RETRAIN_INTERVAL', 3600))  # 1 heure
        self.min_samples = 1000  # Minimum d'√©chantillons pour entra√Æner
        
        self.logger.info("üß† Initialisation du module ML Trainer")
    
    def start(self):
        """D√©marre le thread d'entra√Ænement"""
        if self.thread is None or not self.thread.is_alive():
            self.running = True
            self.thread = threading.Thread(target=self._training_loop, daemon=True)
            self.thread.start()
            self.logger.info("‚úÖ ML Trainer d√©marr√©")
    
    def stop(self):
        """Arr√™te le thread d'entra√Ænement"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
            self.logger.info("üõë ML Trainer arr√™t√©")
    
    def _training_loop(self):
        """Boucle principale d'entra√Ænement"""
        while self.running:
            try:
                self.logger.info("üîÑ D√©marrage de l'entra√Ænement ML...")
                
                with self.app.app_context():
                    # Extraire les features
                    X, y = self._extract_training_data()
                    
                    if len(X) >= self.min_samples:
                        # Entra√Æner le mod√®le Isolation Forest (non supervis√©)
                        self._train_isolation_forest(X)
                        
                        # Entra√Æner le mod√®le supervis√© si on a des labels
                        if y is not None and len(y) > 100:
                            self._train_classifier(X, y)
                        
                        self.logger.info("‚úÖ Entra√Ænement ML termin√©")
                    else:
                        self.logger.info(f"‚è≥ Pas assez de donn√©es: {len(X)} < {self.min_samples}")
                
                # Attendre avant le prochain entra√Ænement
                for _ in range(self.retrain_interval):
                    if not self.running:
                        break
                    time.sleep(1)
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erreur entra√Ænement ML: {e}")
                time.sleep(300)
    
    def _extract_training_data(self):
        """
        Extrait les donn√©es d'entra√Ænement depuis les flux r√©seau
        """
        # P√©riode d'entra√Ænement: 30 derniers jours
        end = datetime.utcnow()
        start = end - timedelta(days=30)
        
        # R√©cup√©rer les flux
        flows = NetworkFlow.query.filter(
            NetworkFlow.ts.between(start, end)
        ).limit(10000).all()
        
        if len(flows) < 100:
            return [], None
        
        # Extraire les features
        features = []
        labels = []
        
        for flow in flows:
            feature_vector = self._extract_features(flow)
            features.append(feature_vector)
            
            # V√©rifier si ce flux a g√©n√©r√© une alerte
            alert = Alert.query.filter_by(flow_id=flow.id).first()
            labels.append(1 if alert else 0)
        
        return np.array(features), np.array(labels)
    
    def _extract_features(self, flow):
        """
        Extrait les features d'un flux pour le ML
        """
        return [
            flow.orig_bytes or 0,
            flow.resp_bytes or 0,
            flow.duration or 0,
            flow.source_port or 0,
            flow.dest_port or 0,
            1 if flow.source_is_internal else 0,
            1 if flow.dest_is_internal else 0,
            hash(flow.protocol or '') % 100,  # Encodage simple du protocole
            flow.ts.hour,  # Heure de la journ√©e
            flow.ts.weekday(),  # Jour de la semaine
        ]
    
    def _train_isolation_forest(self, X):
        """
        Entra√Æne un mod√®le Isolation Forest (d√©tection d'anomalies non supervis√©e)
        """
        self.logger.info("üå≤ Entra√Ænement Isolation Forest...")
        
        # Normalisation
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Mod√®le
        model = IsolationForest(
            contamination=0.1,  # 10% d'anomalies
            random_state=42,
            n_estimators=100
        )
        
        model.fit(X_scaled)
        
        # Sauvegarde
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        joblib.dump(scaler, f"{self.models_path}/scaler_if_{timestamp}.joblib")
        joblib.dump(model, f"{self.models_path}/isolation_forest_{timestamp}.joblib")
        
        # Garder une copie comme mod√®le courant
        joblib.dump(scaler, f"{self.models_path}/scaler_if_latest.joblib")
        joblib.dump(model, f"{self.models_path}/isolation_forest_latest.joblib")
        
        # Publier l'√©v√©nement
        bus.publish('ml:model_updated', {
            'model_type': 'isolation_forest',
            'timestamp': timestamp,
            'samples': len(X)
        })
        
        self.logger.info(f"üíæ Mod√®le Isolation Forest sauvegard√© ({len(X)} √©chantillons)")
    
    def _train_classifier(self, X, y):
        """
        Entra√Æne un classifieur supervis√© (Random Forest)
        """
        self.logger.info("üå≤ Entra√Ænement Random Forest Classifier...")
        
        # Normalisation
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )
        
        # Mod√®le
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        
        model.fit(X_train, y_train)
        
        # √âvaluation
        score = model.score(X_test, y_test)
        self.logger.info(f"üìä Pr√©cision du mod√®le: {score:.2f}")
        
        # Sauvegarde
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        joblib.dump(scaler, f"{self.models_path}/scaler_rf_{timestamp}.joblib")
        joblib.dump(model, f"{self.models_path}/random_forest_{timestamp}.joblib")
        
        # Garder une copie comme mod√®le courant
        joblib.dump(scaler, f"{self.models_path}/scaler_rf_latest.joblib")
        joblib.dump(model, f"{self.models_path}/random_forest_latest.joblib")
        
        # Publier l'√©v√©nement
        bus.publish('ml:model_updated', {
            'model_type': 'random_forest',
            'timestamp': timestamp,
            'accuracy': score,
            'samples': len(X)
        })

# Instance singleton
trainer = None

def init_trainer(app):
    global trainer
    trainer = MLTrainer(app)
    trainer.start()
    return trainer

def get_trainer():
    return trainer